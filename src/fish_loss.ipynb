{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf15f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import _init_paths\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from detectors.detector_factory import detector_factory\n",
    "from datasets.dataset_factory import get_dataset\n",
    "from models.decode import ddd_decode\n",
    "from utils.debugger import Debugger\n",
    "from opts import opts\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3cd750f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.image import transform_preds\n",
    "from trains.train_factory import train_factory\n",
    "from models.model import create_model, load_model, save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7efad68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.utils import _transpose_and_gather_feat\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52588e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '../models/BIG_500K_full_3d.pth'\n",
    "MODEL_PATH = '../exp/ddd/fish_val/model_last.pth'\n",
    "TASK = 'fish3d'\n",
    "DATASET = 'kitti'\n",
    "IMG_PATH = '../data/kitti/images/trainval/000079.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73adc3a8",
   "metadata": {},
   "source": [
    "# Dataset Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ffb6343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fix size testing.\n",
      "training chunk_sizes: [8]\n",
      "The output will be saved to  /home/alfin/Documents/deep_learning/production/centernet_3d_fish/src/lib/../../exp/fish/3dop\n",
      "heads {'hm': 1, 'reg': 2, 'dep': 1, 'dim': 3, 'rot': 4, 'wh': 2, 'reid': 128}\n",
      "heads {'hm': 1, 'reg': 2, 'dep': 1, 'dim': 3, 'rot': 4, 'wh': 2, 'reid': 128}\n"
     ]
    }
   ],
   "source": [
    "Dataset = get_dataset('fish_sim', 'fish')\n",
    "\n",
    "opt = opts().init(['fish','--exp_id','3dop','--dataset','fish_sim','--kitti_split','3dop','--batch_size','8','--num_epochs','70','--lr_step','45,60','--gpus','0'])\n",
    "opt = opts().update_dataset_info_and_set_heads(opt, Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "864ad688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> initializing fish 3dop, val data.\n",
      "loading annotations into memory...\n",
      "Done (t=0.02s)\n",
      "creating index...\n",
      "index created!\n",
      "Loaded val 300 samples\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset(opt, 'val')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    ds, \n",
    "    batch_size=1, \n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb0891b",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d12358b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m detector \u001b[38;5;241m=\u001b[39m \u001b[43mdetector_factory\u001b[49m\u001b[43m[\u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m debugger \u001b[38;5;241m=\u001b[39m Debugger(dataset\u001b[38;5;241m=\u001b[39mdetector\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mdataset, ipynb\u001b[38;5;241m=\u001b[39m(detector\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mdebug\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m3\u001b[39m),\n\u001b[1;32m      3\u001b[0m                         theme\u001b[38;5;241m=\u001b[39mdetector\u001b[38;5;241m.\u001b[39mopt\u001b[38;5;241m.\u001b[39mdebugger_theme)\n",
      "File \u001b[0;32m~/Documents/deep_learning/production/centernet_3d_fish/src/lib/detectors/fish.py:24\u001b[0m, in \u001b[0;36mFishDetector.__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, opt):\n\u001b[0;32m---> 24\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mFishDetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalib \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m707.0493\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m604.0814\u001b[39m, \u001b[38;5;241m45.75831\u001b[39m],\n\u001b[1;32m     26\u001b[0m                          [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m707.0493\u001b[39m, \u001b[38;5;241m180.5066\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.3454157\u001b[39m],\n\u001b[1;32m     27\u001b[0m                          [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1.\u001b[39m, \u001b[38;5;241m0.004981016\u001b[39m]], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Documents/deep_learning/production/centernet_3d_fish/src/lib/detectors/base_detector.py:25\u001b[0m, in \u001b[0;36mBaseDetector.__init__\u001b[0;34m(self, opt)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCreating model...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m create_model(opt\u001b[38;5;241m.\u001b[39march, opt\u001b[38;5;241m.\u001b[39mheads, opt\u001b[38;5;241m.\u001b[39mhead_conv)\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mto(opt\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Documents/deep_learning/production/centernet_3d_fish/src/lib/models/model.py:34\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model, model_path, optimizer, resume, lr, lr_step)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model, model_path, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m     32\u001b[0m                lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, lr_step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     33\u001b[0m   start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 34\u001b[0m   checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloc\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloaded \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, epoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(model_path, checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[1;32m     36\u001b[0m   state_dict_ \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/CenterNet/lib/python3.8/site-packages/torch/serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    697\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    701\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    702\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/.conda/envs/CenterNet/lib/python3.8/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/.conda/envs/CenterNet/lib/python3.8/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "detector = detector_factory[opt.task](opt)\n",
    "debugger = Debugger(dataset=detector.opt.dataset, ipynb=(detector.opt.debug==3),\n",
    "                        theme=detector.opt.debugger_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5c2af89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = detector.model\n",
    "model = create_model(opt.arch, opt.heads, opt.head_conv)\n",
    "optimizer = torch.optim.Adam(model.parameters(), opt.lr)\n",
    "\n",
    "Trainer = train_factory[TASK]\n",
    "trainer = Trainer(opt, model, optimizer)\n",
    "trainer.set_device(opt.gpus, opt.chunk_sizes, opt.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7308865",
   "metadata": {},
   "source": [
    "# LOSS ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19ec0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (3, 512, 512) <class 'numpy.ndarray'>\n",
      "hm (3, 128, 128) <class 'numpy.ndarray'>\n",
      "ind (40,) <class 'numpy.ndarray'>\n",
      "dep (40, 1) <class 'numpy.ndarray'>\n",
      "dim (40, 3) <class 'numpy.ndarray'>\n",
      "rotX (40, 1) <class 'numpy.ndarray'>\n",
      "rotY (40, 1) <class 'numpy.ndarray'>\n",
      "reg_mask (40,) <class 'numpy.ndarray'>\n",
      "reg (40, 2) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for key in ds[0].keys():\n",
    "    if type(ds[0][key]) != dict:\n",
    "        print(key,ds[0][key].shape,type(ds[0][key])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36df5cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03b3e8ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['hm', 'dep', 'rotX', 'rotY', 'dim', 'reg'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_input, meta = detector.pre_process(np.moveaxis(data['input'], 0, -1), detector.scales)\n",
    "img_input = img_input.to(detector.opt.device)\n",
    "output = detector.model(img_input)[-1]\n",
    "\n",
    "output['hm'] = output['hm'].sigmoid_()\n",
    "output['dep'] = 1. / (output['dep'].sigmoid() + 1e-6) - 1.\n",
    "# wh = output['wh'] if detector.opt.reg_bbox else None\n",
    "reg = output['reg'] if detector.opt.reg_offset else None\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a473c5b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'headingX'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m target_res \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheading_resX\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# converting outputs\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m headingX \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mheadingX\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     10\u001b[0m ind \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(np\u001b[38;5;241m.\u001b[39mexpand_dims(np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mind\u001b[39m\u001b[38;5;124m'\u001b[39m]), axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m))\u001b[38;5;241m.\u001b[39mtype(torch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m     11\u001b[0m headingX \u001b[38;5;241m=\u001b[39m _transpose_and_gather_feat(headingX, ind)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'headingX'"
     ]
    }
   ],
   "source": [
    "num_heading_bin = 12\n",
    "\n",
    "# converting dataset\n",
    "mask = torch.Tensor(np.expand_dims(np.array(data['rot_mask']), axis = 1))\n",
    "target_bin = torch.Tensor(data['heading_binX']).type(torch.long)\n",
    "target_res = torch.Tensor(data['heading_resX'])\n",
    "\n",
    "# converting outputs\n",
    "headingX = output['headingX'].detach().cpu()\n",
    "ind = torch.Tensor(np.expand_dims(np.array(data['ind']), axis = 0)).type(torch.int64)\n",
    "headingX = _transpose_and_gather_feat(headingX, ind)\n",
    "\n",
    "# reshape\n",
    "headingX = headingX.view(-1, num_heading_bin*2)\n",
    "target_bin = target_bin.view(-1, 1)\n",
    "target_res = target_res.view(-1, 1)\n",
    "\n",
    "print(headingX.shape,target_bin.shape,target_res.shape,mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c69d4f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headingX' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m heading_input_cls \u001b[38;5;241m=\u001b[39m \u001b[43mheadingX\u001b[49m[:, \u001b[38;5;241m0\u001b[39m:num_heading_bin]\n\u001b[1;32m      2\u001b[0m heading_input_cls[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'headingX' is not defined"
     ]
    }
   ],
   "source": [
    "heading_input_cls = headingX[:, 0:num_heading_bin]\n",
    "heading_input_cls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "4f4b2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract important feature\n",
    "mask_cls = mask.expand_as(heading_input_cls).float()\n",
    "heading_input_cls = heading_input_cls*mask_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d2c0c383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4855)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cross_entropy(heading_input_cls, target_bin[:,0], reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "aaca1e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 2, 2, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_bin[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0ac5e77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 12])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heading_input_cls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7986584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
